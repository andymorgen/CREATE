{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre_processing of the fastq files\n",
    "\n",
    "The following code has been written to split the fastq files into component files/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def hamming_distance(string1,string2):\n",
    "    \"\"\"\n",
    "    The following code is to measure the hamming distance between 2 reads\n",
    "    Input: String 1 and string 2\n",
    "    \n",
    "    Output: Distance(count of mismatches between the 2 strings)\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    for x,y  in zip(string1,string2):\n",
    "        if x!=y:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def fastq_splitter_pairedend(R1file,R2file,Indexfile,BCmapfile,levdist,outdir):\n",
    "    \"\"\"\n",
    "    The following function is to split the sequences into reapective fastq files by index\n",
    "    \"\"\"\n",
    "    import time\n",
    "    time0=time.time()\n",
    "    import gzip\n",
    "    #import BioModules\n",
    "    from itertools import izip\n",
    "    #from BioModules import revcomp\n",
    "    import collections\n",
    "    #import Levenshtein as Lev\n",
    "    import io\n",
    "    counts = collections.defaultdict(int)\n",
    "    totalseqs=0\n",
    "    assigned=0\n",
    "    R1=gzip.open(R1file,'rb')\n",
    "    R2=gzip.open(R2file,'rb')\n",
    "    I1=gzip.open(Indexfile,'rb')\n",
    "    mydict=[]\n",
    "    BCs=[]\n",
    "    counterlist=[]\n",
    "    with open(BCmapfile,'r') as f:\n",
    "        for line in f:\n",
    "            line=line.strip().split('\\t')\n",
    "            BCs.append((line[0],line[1]))\n",
    "            \n",
    "    outfsR1 = dict([(ID, open(outdir+ID + \"_R1.fastq\", \"w\"))\n",
    "                 for ID,seq in BCs])\n",
    "    outfsR2 = dict([(ID, open(outdir+ID + \"_R2.fastq\", \"w\"))\n",
    "                 for ID,seq in BCs])\n",
    "    iterator=enumerate(izip(R1,R2,I1))\n",
    "    \n",
    "    for i, (line1,line2,line3) in iterator:\n",
    "        \n",
    "        totalseqs+=1\n",
    "        R1_ID,R2_ID,I1_ID=line1,line2.rstrip(),line3\n",
    "        seqs=iterator.next()\n",
    "        seq1,seq2,index=seqs[1][0],seqs[1][1].strip(),seqs[1][2][1:]\n",
    "        spacer=iterator.next()\n",
    "        quals=iterator.next()\n",
    "        q1,q2,qI=quals[1][0],quals[1][1][::-1],quals[1][2]\n",
    "        \n",
    "        for ID,BC in BCs: \n",
    "        #Defines the acceptable deviations of the index read from the mapping barcodes\n",
    "        # and looks for kmers in the sequences. Can do various different processing steps here\n",
    "            if hamming_distance(index,BC.strip())<=levdist:\n",
    "                group=ID\n",
    "                assigned+=1\n",
    "                #trim and concatenate reads 1&2 and write to file, can alter the behavior here as desired\n",
    "                outfsR1[group].write(R1_ID.strip()+'\\n')\n",
    "                outfsR1[group].write(seq1.strip()+'\\n')\n",
    "                outfsR1[group].write('+'+'\\n')\n",
    "                outfsR1[group].write(q1.strip()+'\\n')\n",
    "                outfsR2[group].write(R2_ID.strip()+'\\n')\n",
    "                outfsR2[group].write(seq2.strip()+'\\n')\n",
    "                outfsR2[group].write('+'+'\\n')\n",
    "                outfsR2[group].write(q2.strip()+'\\n')\n",
    "                counts[group]+=1\n",
    "                counterlist.append([ID,BC,index])\n",
    "                break   \n",
    "    for i in outfsR1.values():\n",
    "        i.close()\n",
    "    for i in outfsR2.values():\n",
    "        i.close()\n",
    "    print time.time()-time0\n",
    "    #return counterlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5abe9142e7b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mR1file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Undetermined_S0_L001_R1_001.fastq.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mR2file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Undetermined_S0_L001_R2_001.fastq.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mIndexfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Undetermined_S0_L001_I1_001.fastq.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/\")\n",
    "R1file = \"Undetermined_S0_L001_R1_001.fastq.gz\"\n",
    "R2file = \"Undetermined_S0_L001_R2_001.fastq.gz\"\n",
    "Indexfile = \"Undetermined_S0_L001_I1_001.fastq.gz\"\n",
    "BCmapfile = \"map.txt\"\n",
    "levdist = 4\n",
    "outdir = \"BC_Split_Files/\"\n",
    "fastq_splitter_pairedend(R1file,R2file,Indexfile,BCmapfile,levdist,outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n",
      "Command was executed succesfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following code is to merge the different files\n",
    "\n",
    "The implmentation is done using pandaseq\n",
    "\n",
    "Here are the default parameters:\n",
    "\n",
    "\n",
    "The following code is written to merge the fastq files\n",
    "\"\"\"\n",
    "import subprocess\n",
    "import os\n",
    "os.chdir(\"/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/BC_Split_Files/\")\n",
    "split_files = os.listdir(\"/home/thegillgroup/Alaksh/MySeq_Data_Analysis_Pipeline/BC_Split_Files/\")\n",
    "list_barcodes = []\n",
    "for files in split_files:\n",
    "    list_barcodes.append(files[0:-9])\n",
    "list_barcodes = list(set(list_barcodes))\n",
    "list_barcodes.remove('')\n",
    "\n",
    "for barcode in list_barcodes:\n",
    "    for_read_file = barcode + \"_R1.fastq\" #forward read goes here\n",
    "    rev_read_file = barcode + \"_R2.fastq\" #reverse read goes here\n",
    "    output_file = barcode + \"_output.fasta\" #Output file goes here\n",
    "    p = subprocess.call([\"pandaseq\",\"-f\",for_read_file,\"-r\",rev_read_file,\"-w\",output_file])\n",
    "    if p == 0:\n",
    "        print(\"Command was executed succesfully\")\n",
    "    else:\n",
    "        print(\"Command didn't run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following code is to read fasta files:\n",
    "\n",
    "Input: filename\n",
    "output: 2 lists one with sequences and other with ids\n",
    "\"\"\"\n",
    "import os\n",
    "os.chdir(\"/Users/andrewmorgenthaler/Google Drive/MCDB/Courses/Bioinformatics/project/\")\n",
    "def readFasta(filename):\n",
    "    seq_id_list = []\n",
    "    sequences = []\n",
    "    with open(filename) as fh:\n",
    "        while True:\n",
    "            seq_id = fh.readline().rstrip()[1:]\n",
    "            seq = fh.readline().rstrip()\n",
    "            if len(seq) == 0:\n",
    "                break\n",
    "            seq_id_list.append(seq_id)\n",
    "            sequences.append(seq)\n",
    "    return seq_id_list,sequences\n",
    "seq_id_list,sequences = readFasta(\"CREATElibrary_folAsaturation.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usearch_Output/BC01_folA_s1_T0_usearch.txt\n",
      "Usearch completed successfuly for -data/BC01_folA_s1_T0_merged.fastq\n",
      "Usearch_Output/BC04_folA_s1_TMP_usearch.txt\n",
      "Usearch completed successfuly for -data/BC04_folA_s1_TMP_merged.fastq\n",
      "Usearch_Output/BC05_folA_s2_T0_usearch.txt\n",
      "Usearch completed successfuly for -data/BC05_folA_s2_T0_merged.fastq\n",
      "Usearch_Output/BC08_folA_s2_TMP_usearch.txt\n",
      "Usearch completed successfuly for -data/BC08_folA_s2_TMP_merged.fastq\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "os.chdir(\"/Users/andrewmorgenthaler/Google Drive/MCDB/Courses/Bioinformatics/project/\")\n",
    "split_files = os.listdir(\"/Users/andrewmorgenthaler/Google Drive/MCDB/Courses/Bioinformatics/project/data/\")\n",
    "file_list = []\n",
    "\n",
    "\n",
    "def usearch_function(file_name,output_filename):\n",
    "    userfields = \"query+target+id+alnlen+mism+opens+qlo+qhi+tlo+thi+evalue+bits+qrow+trow+qrowdots+tstrand+qstrand\"\n",
    "    p = subprocess.call([\"/Users/andrewmorgenthaler/Google Drive/MCDB/Courses/Bioinformatics/project/usearch9.2.64\",\"-usearch_global\",file_name,\"-db\",\"CREATElibrary_folAsaturation.fasta\",\"-id\",\"0.8\",\\\n",
    "                        \"-strand\",\"both\",\"-userout\",output_filename,\"-userfields\",\\\n",
    "                        userfields])\n",
    "    return p\n",
    "\n",
    "for files in split_files:\n",
    "    input_file = 'data/'+files\n",
    "    output_file = 'Usearch_Output/'+files[0:-13]+\"_usearch.txt\"\n",
    "    print output_file\n",
    "    p = usearch_function(input_file,output_file)\n",
    "    if p == 0:\n",
    "        print(\"Usearch completed successfuly for -\" + input_file)\n",
    "    else:\n",
    "        print(\"Usearch not done for -\" + input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
